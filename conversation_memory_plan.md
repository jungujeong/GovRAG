# Conversation Memory Enhancement Plan

## 1. 배경 및 목표
- 다중 턴 대화에서 모델이 직전 질의/응답을 제대로 기억하지 못해 후속 질문에 실패하는 문제가 반복적으로 발생함.
- 목적은 **세션 단위로 핵심 맥락을 추출·보존**하고, **질문을 검색 친화적으로 재작성**하여 RAG 파이프라인이 이전 턴 정보를 활용하도록 개선하는 것.
- 성공 기준은 (1) 다중 턴 QA 시 이전 턴 정보가 반영된 응답 생성, (2) 회상 실패율 감소, (3) 테스트 및 QA 평가에서 회귀 없음.

## 2. 현황 진단
- `ChatSession`은 단순 메시지 로그만 저장하고 요약/엔터티 같은 메타정보 부족.
- `HybridRetriever`는 직전 발화 맥락 없이 사용자 질의만으로 검색 → 후속 질문의 참조 관계가 끊김.
- `OllamaGenerator.generate_with_context`는 최근 메시지를 일부 포함하지만, 토큰 한계 때문에 긴 세션에서 맥락 손실.
- 회상 실패 시 사용자 경험이 크게 저하되며, 재질문/반복이 빈번.

## 3. 제안 기능 요약
1. **세션 메모리 확장**: `conversation_summary`, `recent_entities` 등 요약 필드를 세션 모델에 추가.
2. **대화 요약기 서비스**: 마지막 턴과 기존 요약을 입력으로 새 요약/키워드를 생성.
3. **질의 재작성기**: 요약 + 최근 발화를 기반으로 사용자의 후속 질문을 독립형 검색 질의로 재작성.
4. **생성 프롬프트 증강**: 생성 단계에서 요약/엔터티를 시스템 메시지 선행 정보로 포함.
5. **턴 종료 후 메모리 갱신**: 어시스턴트 응답 후 세션 요약/엔터티 저장.
6. **테스트 및 검증**: 다중 턴 QA, 요약 실패, 페일오버 시나리오 테스트 케이스 추가.

## 4. 상세 설계
### 4.1 세션 데이터 모델
- `backend/models/session.py`
  - `ChatSession`에 `conversation_summary: Optional[str]`, `recent_entities: Optional[List[str]]` 필드 추가.
  - `to_dict()` / 복원 로직 업데이트, `get_context()`는 기존대로 유지.
- `backend/services/session_manager.py`
  - 세션 직렬화/역직렬화 업데이트.
  - `add_message()` 또는 전용 메서드에서 요약 필드 저장 지원.
  - `get_session_context()` 확장: 기본 메시지 로그 + 요약 반환 옵션 제공.

### 4.2 대화 요약기 (`backend/rag/conversation_summarizer.py` 신규)
- 책임: 기존 요약 + 최신 사용자/어시스턴트 메시지를 입력받아 `conversation_summary`, `recent_entities` 생성.
- 구현 방식
  - `generate_summary(messages: List[Message], previous_summary: str | None) -> SummaryResult` 함수 노출.
  - LLM 호출 실패 시 최근 N개 메시지 연결 + 간단 키워드 추출(예: 명사 빈도 기반)로 폴백.
  - 재사용 가능하도록 동기/비동기 인터페이스 정리.
- 구성 요소
  - `SummaryResult` 데이터클래스: `summary_text`, `entities`(리스트), `used_fallback` 플래그.
  - 프롬프트 템플릿 정의: 대화 흐름, 정책, 출력 형식(예: 요약 150자 이내, 엔터티 최대 5개).

### 4.3 질의 재작성기 (`backend/rag/query_rewriter.py` 신규)
- 책임: 후속 질문을 독립형 검색 질의 + 서브 질의로 변환.
- 핵심 함수: `rewrite(query, recent_messages, summary, entities) -> RewriteResult`
  - `recent_messages`: 마지막 3~4개의 메시지 제공.
  - `summary`: 위 요약 서비스 결과 문자열.
  - 산출: `search_query`, `reasoning`(로그/디버깅용), 폴백 여부.
- 구현상 고려
  - LLM 실패 시 원문 질문을 그대로 반환.
  - 재작성 시 주요 엔터티 포함, 모호한 지시어(“그 프로그램”)를 바꿔 주도록 프롬프트 설계.

### 4.4 라우터 & 파이프라인 통합
- `backend/routers/chat.py`
  - 요청 수신 시 `session_manager.get_session()`으로 요약/엔터티 확보.
  - `QueryRequest` 처리 흐름에 재작성 단계 삽입 → `HybridRetriever.retrieve()` 인자로 `rewritten_query` 전달.
  - 생성 단계 (`generator.generate_with_context`) 호출 시 시스템 메시지 앞부분에 요약/엔터티 삽입.
  - 응답 생성 후 `conversation_summarizer` 호출하여 새 요약 생성, `session_manager` 통해 세션 업데이트.
  - 스트리밍 모드에서도 동일 로직 적용, 취소 이벤트와 경합 처리 주의.
- `HybridRetriever`
  - public API는 유지하되, 재작성 질의가 있을 경우 해당 문자열 사용. 원문 질의는 백업.

### 4.5 설정 및 폴백 전략
- `.env` / `config.py`
  - 요약 길이, 재작성 토큰 제한, 폴백 메시지 수 등 구성 가능 값 추가 검토.
- 실패 대응
  - 요약/재작성 실패 시 로그 남기고 기존 단일 턴 흐름으로 폴백.
  - 세션 저장 실패 대비 예외 처리, 요약 길이 초과 시 자르기.

## 5. 구현 단계
1. **스키마 업데이트**
   - `ChatSession`, `SessionManager` 구조 변경 및 마이그레이션 (기존 JSON 로드 시 기본값 제공).
2. **요약기 모듈 추가**
   - 프롬프트 초안 작성 → LLM 호출/폴백 구현 → 단위 테스트 작성.
3. **질의 재작성기 모듈 추가**
   - 재작성 프롬프트, 결과 파서, 폴백 처리 구현.
4. **라우터 통합**
   - `chat.py`와 스트리밍 엔드포인트 수정, 요약/재작성 호출 연결.
5. **세션 저장 확장**
   - 응답 완료 후 요약/엔터티 저장, 세션 직렬화 검증.
6. **테스트 강화**
   - `tests/test_multi_session.py` 또는 신규 테스트에 다중 턴 시나리오 추가.
   - 폴백 경로, 재작성 실패, 요약 없는 상태에서도 동작하는지 확인.
7. **회귀 검증**
   - `pytest tests -q`, `make qa`로 기존 품질 지표 확인.

## 6. 테스트 전략
- **단위 테스트**
  - 요약기: 입력 메시지 → 요약/엔터티 정확성 및 폴백 동작.
  - 재작성기: 지시어가 포함된 질문 → 명시적 질의로 변환 확인.
- **통합 테스트**
  - 다중 턴 대화에서 동일 세션 내 후속 질문이 이전 답변을 참조하는지 확인.
  - 스트리밍 모드에서 중도 취소 후 요약 저장이 올바른지 검증.
- **QA 평가**
  - `make qa`로 골든셋 실행, 회상 관련 지표 추적.

## 7. 일정 및 마일스톤
- **Day 1**: 스키마/세션 매니저 업데이트, 요약기 기본 구현.
- **Day 2**: 재작성기 구현 및 단위 테스트.
- **Day 3**: 라우터/생성기 통합, 스트리밍 경로 반영.
- **Day 4**: 통합 테스트, 성능 튜닝, QA 실행.

## 8. 리스크 및 완화 전략
- **LLM 호출 지연**: 요약/재작성 추가로 응답 시간이 늘어날 수 있음 → 캐싱, 토큰 제한, 비동기 호출 최적화.
- **요약 부정확**: 잘못된 요약이 누적될 위험 → 마지막 N개 메시지 직접 포함하는 폴백 유지.
- **기존 데이터 호환성**: 기존 세션 JSON에 새 필드 부재 → 로드 시 기본값 처리로 대응.
- **테스트 복잡도 증가**: 멀티턴 플로우 테스트 시간 증가 → 핵심 시나리오 중심으로 최소화.

## 9. 후속 과제
- 요약/재작성 결과를 프론트엔드에서 노출하여 디버깅 용이성 확보.
- 장기적으로 벡터 DB에 요약을 동기화하거나, 세션 기반 개인화 기능 확장 검토.
